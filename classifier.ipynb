{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ce074d-8d84-47b3-bfa6-12d0b330358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from  shutil import copyfile\n",
    "import random\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5159ab-1b77-4eeb-8e02-12e1619b477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59feca90-1790-4b77-8865-5245354e30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31aa2d67-c086-451d-aaac-8e966ff5e2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6535 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=32,\n",
    "                                                     directory=\"./weather_dataset/train\",\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(128, 128),\n",
    "                                                     class_mode='categorical'\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4387d506-44b4-46e3-8e3b-f3e9528897e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_image_generator.flow_from_directory(\n",
    "                                                  directory=\"./weather_dataset/test\",\n",
    "                                                  target_size=(128, 128),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0480675-c2f2-4feb-8fd3-1b89dffa64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83136f6-d216-4adf-823c-cf43e55c2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 22:57:21.996039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64:/opt/sw/other/apps/cuda/12.2.0/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2023-12-05 22:57:21.996074: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-05 22:57:21.996427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(input_shape = (128, 128, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b16ade6-9181-44ea-bdf1-7adfe646235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8c8dba-f6fe-4257-b72f-5d57bf44bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten , GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "164001ba-26f3-4d61-b09f-5847e8eded8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef6e47a-bc36-42ad-9f04-0bb652a1afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a15da7-b551-4173-a19b-b0c23121b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e1fc8d-f208-4749-87f9-7a0b07c67bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre.compile(optimizer=keras.optimizers.Adam(0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "277f2098-09de-4654-9021-d7c4b8cb0655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "205/205 [==============================] - 88s 427ms/step - loss: 0.7001 - accuracy: 0.7252 - val_loss: 0.4992 - val_accuracy: 0.8140\n",
      "Epoch 2/30\n",
      "205/205 [==============================] - 87s 422ms/step - loss: 0.5255 - accuracy: 0.7940 - val_loss: 0.4659 - val_accuracy: 0.8326\n",
      "Epoch 3/30\n",
      "205/205 [==============================] - 87s 422ms/step - loss: 0.4947 - accuracy: 0.8080 - val_loss: 0.4452 - val_accuracy: 0.8326\n",
      "Epoch 4/30\n",
      "205/205 [==============================] - 86s 421ms/step - loss: 0.4565 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8651\n",
      "Epoch 5/30\n",
      "205/205 [==============================] - 87s 422ms/step - loss: 0.4497 - accuracy: 0.8248 - val_loss: 0.3738 - val_accuracy: 0.8744\n",
      "Epoch 6/30\n",
      "205/205 [==============================] - 86s 419ms/step - loss: 0.4273 - accuracy: 0.8346 - val_loss: 0.3874 - val_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "205/205 [==============================] - 87s 422ms/step - loss: 0.4114 - accuracy: 0.8409 - val_loss: 0.3483 - val_accuracy: 0.8744\n",
      "Epoch 8/30\n",
      "205/205 [==============================] - 86s 419ms/step - loss: 0.4032 - accuracy: 0.8461 - val_loss: 0.3048 - val_accuracy: 0.8791\n",
      "Epoch 9/30\n",
      "205/205 [==============================] - 86s 417ms/step - loss: 0.4007 - accuracy: 0.8398 - val_loss: 0.4071 - val_accuracy: 0.8372\n",
      "Epoch 10/30\n",
      "205/205 [==============================] - 86s 421ms/step - loss: 0.3826 - accuracy: 0.8496 - val_loss: 0.3268 - val_accuracy: 0.8884\n",
      "Epoch 11/30\n",
      "205/205 [==============================] - 86s 420ms/step - loss: 0.3707 - accuracy: 0.8546 - val_loss: 0.3001 - val_accuracy: 0.8837\n",
      "Epoch 12/30\n",
      "205/205 [==============================] - 87s 424ms/step - loss: 0.3617 - accuracy: 0.8609 - val_loss: 0.3033 - val_accuracy: 0.8837\n",
      "Epoch 13/30\n",
      "205/205 [==============================] - 86s 420ms/step - loss: 0.3665 - accuracy: 0.8592 - val_loss: 0.2981 - val_accuracy: 0.8791\n",
      "Epoch 14/30\n",
      "205/205 [==============================] - 86s 419ms/step - loss: 0.3538 - accuracy: 0.8574 - val_loss: 0.2921 - val_accuracy: 0.8698\n",
      "Epoch 15/30\n",
      "205/205 [==============================] - 85s 413ms/step - loss: 0.3492 - accuracy: 0.8660 - val_loss: 0.3139 - val_accuracy: 0.8744\n",
      "Epoch 16/30\n",
      "205/205 [==============================] - 86s 417ms/step - loss: 0.3394 - accuracy: 0.8710 - val_loss: 0.3033 - val_accuracy: 0.8837\n",
      "Epoch 17/30\n",
      "205/205 [==============================] - 87s 422ms/step - loss: 0.3293 - accuracy: 0.8725 - val_loss: 0.2605 - val_accuracy: 0.9023\n",
      "Epoch 18/30\n",
      "205/205 [==============================] - 87s 423ms/step - loss: 0.3259 - accuracy: 0.8756 - val_loss: 0.2354 - val_accuracy: 0.9070\n",
      "Epoch 19/30\n",
      "205/205 [==============================] - 86s 418ms/step - loss: 0.3214 - accuracy: 0.8692 - val_loss: 0.2403 - val_accuracy: 0.8884\n",
      "Epoch 20/30\n",
      "205/205 [==============================] - 87s 422ms/step - loss: 0.3247 - accuracy: 0.8716 - val_loss: 0.2245 - val_accuracy: 0.8977\n",
      "Epoch 21/30\n",
      "205/205 [==============================] - 85s 416ms/step - loss: 0.3063 - accuracy: 0.8836 - val_loss: 0.2535 - val_accuracy: 0.9070\n",
      "Epoch 22/30\n",
      "205/205 [==============================] - 85s 413ms/step - loss: 0.3067 - accuracy: 0.8794 - val_loss: 0.2306 - val_accuracy: 0.9023\n",
      "Epoch 23/30\n",
      "205/205 [==============================] - 85s 415ms/step - loss: 0.2982 - accuracy: 0.8878 - val_loss: 0.2387 - val_accuracy: 0.9070\n",
      "Epoch 24/30\n",
      "205/205 [==============================] - 86s 418ms/step - loss: 0.2986 - accuracy: 0.8857 - val_loss: 0.2425 - val_accuracy: 0.9163\n",
      "Epoch 25/30\n",
      "205/205 [==============================] - 86s 417ms/step - loss: 0.2878 - accuracy: 0.8875 - val_loss: 0.2359 - val_accuracy: 0.9116\n",
      "Epoch 26/30\n",
      "205/205 [==============================] - 85s 415ms/step - loss: 0.2846 - accuracy: 0.8891 - val_loss: 0.2184 - val_accuracy: 0.9070\n",
      "Epoch 27/30\n",
      "205/205 [==============================] - 85s 415ms/step - loss: 0.2746 - accuracy: 0.8935 - val_loss: 0.2119 - val_accuracy: 0.9116\n",
      "Epoch 28/30\n",
      "205/205 [==============================] - 86s 421ms/step - loss: 0.2833 - accuracy: 0.8904 - val_loss: 0.2378 - val_accuracy: 0.9070\n",
      "Epoch 29/30\n",
      "205/205 [==============================] - 85s 416ms/step - loss: 0.2700 - accuracy: 0.8926 - val_loss: 0.2353 - val_accuracy: 0.9023\n",
      "Epoch 30/30\n",
      "205/205 [==============================] - 85s 416ms/step - loss: 0.2706 - accuracy: 0.8946 - val_loss: 0.1950 - val_accuracy: 0.9163\n"
     ]
    }
   ],
   "source": [
    "his = model_pre.fit(train_data_gen,validation_data=test_generator, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe59667d-2543-4b4e-a959-7b4f7f973b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d19b59ce-5f2d-4526-b17b-db3673dd5b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "eval_images = eval_gen.flow_from_directory(\n",
    "                                                  directory=\"./temp/\",\n",
    "                                                  target_size=(256, 256),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ea2ccb-af6f-4cba-8591-b9ae7fe3ea7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_images.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91e4ca59-7f7b-44b6-a7db-bf6261877c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 1s/step - loss: 0.4879 - accuracy: 0.8378\n"
     ]
    }
   ],
   "source": [
    "pred1 = model_pre.evaluate(eval_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dccb4-1062-4ec2-9bf3-4a40ff1c2214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e19455-eb0b-412e-9490-162fb029bb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6e2a4-b294-43e5-8086-cb82437ab1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2172fa-916d-48c0-9527-090e90c46c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4f0c9-27f1-49af-98f7-a27561633280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "470c2649-e0a0-4d88-b921-677acd249af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bea12d6-cd43-42a3-96e8-9f74eb9ed6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model_res = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25d01d1b-6b90-4f32-9db9-4e0c393a84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_res.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "977cd9da-a808-48bd-a9db-99b56d8b4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(base_model_res.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb0e9090-9a78-4815-8499-5c364e9122f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(inputs=base_model_res.input, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c493582-ce34-46cb-9cde-42568b8638a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 44s 205ms/step - loss: 1.2393 - accuracy: 0.4239 - val_loss: 1.3715 - val_accuracy: 0.3209\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 42s 204ms/step - loss: 1.1131 - accuracy: 0.4939 - val_loss: 1.2824 - val_accuracy: 0.3721\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 41s 202ms/step - loss: 1.0477 - accuracy: 0.5634 - val_loss: 1.1434 - val_accuracy: 0.4884\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 41s 201ms/step - loss: 0.9978 - accuracy: 0.5802 - val_loss: 1.1157 - val_accuracy: 0.5163\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 41s 201ms/step - loss: 0.9577 - accuracy: 0.5986 - val_loss: 1.0492 - val_accuracy: 0.5907\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 41s 201ms/step - loss: 0.9283 - accuracy: 0.6186 - val_loss: 1.0050 - val_accuracy: 0.6093\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 42s 202ms/step - loss: 0.9101 - accuracy: 0.6263 - val_loss: 0.9797 - val_accuracy: 0.6047\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 41s 202ms/step - loss: 0.8952 - accuracy: 0.6330 - val_loss: 0.9908 - val_accuracy: 0.5581\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 42s 203ms/step - loss: 0.8823 - accuracy: 0.6369 - val_loss: 0.9694 - val_accuracy: 0.5767\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 42s 203ms/step - loss: 0.8585 - accuracy: 0.6430 - val_loss: 0.9599 - val_accuracy: 0.6140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c3071d520>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_data_gen,\n",
    "          epochs=10,\n",
    "          validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a9e72-62ba-43dc-ad5f-1bd9ce5d512b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
